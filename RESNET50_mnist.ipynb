{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RESNET50 mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4epPJQDna_j",
        "colab_type": "text"
      },
      "source": [
        "# RESNET50 model for MNIST Dataset\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ShO6okPXrN",
        "colab_type": "text"
      },
      "source": [
        "![](https://cdn-images-1.medium.com/max/1600/1*hEU7S-EiVqcmtAlj6kgfRA.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQgUBCVKntoo",
        "colab_type": "text"
      },
      "source": [
        "## Architecture\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG8aIOaVRFHr",
        "colab_type": "text"
      },
      "source": [
        "![](https://neurohive.io/wp-content/uploads/2019/01/resnet-architectures-34-101.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN_tOybUnqPV",
        "colab_type": "text"
      },
      "source": [
        "## Code\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNucnjq2xDIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "ae9ea0b2-90d3-45db-fceb-e7550266f4f4"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential , Model\n",
        "from keras.layers import Input ,  Dense, Dropout, Flatten , Activation , ZeroPadding2D\n",
        "from keras.layers import Conv2D, MaxPooling2D  , Add , AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "\n",
        "batch_size = 256\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################################################################\n",
        "\n",
        "\n",
        "def ident_block(input_X , filters , kernels):\n",
        "\n",
        "  K1 , K2 , K3 = kernels\n",
        "  F1 , F2 , F3 = filters\n",
        "  x_shortcut = input_X\n",
        "  \n",
        "  conv1 = Conv2D(filters= F1 , kernel_size= (K1 , K1), padding = 'same')(input_X)\n",
        "  bn1 = BatchNormalization()(conv1)\n",
        "  act1 = Activation('relu')(bn1)\n",
        "  \n",
        "  conv2 = Conv2D(filters= F2 , kernel_size= (K2 , K2) , padding='same')(act1)\n",
        "  bn2 = BatchNormalization()(conv2)\n",
        "  act2 = Activation('relu')(bn2)\n",
        "  \n",
        "  conv3 = Conv2D(filters= F3 , kernel_size= (K3,K3), padding = 'same')(act2)\n",
        "  bn3 = BatchNormalization()(conv3)\n",
        "  \n",
        "  X_add = Add()([input_X , bn3])\n",
        "  act3 = Activation('relu')(X_add)\n",
        "\n",
        "  return act3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def conv_block(input_X , filters , kernels):\n",
        "  \n",
        "  \n",
        "  K1 , K2 , K3 = kernels\n",
        "  F1 , F2 , F3 = filters\n",
        "  x_shortcut = input_X\n",
        "  \n",
        "  conv1 = Conv2D(filters= F1 , kernel_size = (K1,K1))(input_X)\n",
        "  bn1 = BatchNormalization()(conv1)\n",
        "  act = Activation('relu')(bn1)\n",
        "  \n",
        "  conv2 = Conv2D(filters= F2 , kernel_size= (K2,K2) , padding= 'same')(act)\n",
        "  bn2 = BatchNormalization()(conv2)\n",
        "  act2 = Activation('relu')(bn2)\n",
        "   \n",
        "  conv3 = Conv2D(filters= F3 , kernel_size= (K3 , K3) , padding= 'same')(act2)\n",
        "  bn3 = BatchNormalization()(conv3)\n",
        "   \n",
        "  shcut_conv1 = Conv2D(filters= F3 , kernel_size= (1,1) , padding = 'same')(x_shortcut)\n",
        "  shcut_bn1 = BatchNormalization()(shcut_conv1)\n",
        "  \n",
        "  X_add = Add()([shcut_bn1 , bn3])\n",
        "  act3 = Activation('relu')(X_add)\n",
        "  \n",
        "  return act3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Input\n",
        "X_in = Input(input_shape)\n",
        "\n",
        "# Zero Padding\n",
        "X = ZeroPadding2D((3,3))(X_in)\n",
        "\n",
        "# Stage 1\n",
        "# CONV -> BATCHNORM -> RELU -> POOL\n",
        "conv_1 = Conv2D(filters = 64 , kernel_size= (7,7) ,strides= 2)(X)\n",
        "batch_norm_1 = BatchNormalization()(conv_1)\n",
        "relu_1 = Activation('relu')(batch_norm_1)\n",
        "max_pool_1 = MaxPooling2D(pool_size=(3,3) , strides= 2)(relu_1)\n",
        "\n",
        "# Stage 2\n",
        "# CONV BLOCK -> ID BLOCK\n",
        "conv_2 = conv_block(max_pool_1 , (64,64,256) , (1,3,1))\n",
        "ident_2 = ident_block(conv_2 , (64,64,256) , (1,3,1))\n",
        "ident_3 = ident_block(ident_2 , (64,64,256) , (1,3,1))\n",
        "\n",
        "# Stage 3\n",
        "conv_3 = conv_block(ident_3 , (128,128,512) , (1,3,1))\n",
        "ident_4 = ident_block(conv_3 , (128,128,512) , (1,3,1))\n",
        "ident_5 = ident_block(ident_4 , (128,128,512) , (1,3,1))\n",
        "ident_6 = ident_block(ident_5 , (128,128,512) , (1,3,1))\n",
        "\n",
        "# Stage 4\n",
        "conv_4 = conv_block(ident_6 , (256 , 256 , 1024) , (1,3,1))\n",
        "ident_7 = ident_block(conv_4 , (256 , 256 , 1024) , (1,3,1))\n",
        "ident_8 = ident_block(ident_7 , (256 , 256 , 1024) , (1,3,1))\n",
        "ident_9 = ident_block(ident_8 , (256 , 256 , 1024) , (1,3,1))\n",
        "ident_10 = ident_block(ident_9 , (256 , 256 , 1024) , (1,3,1))\n",
        "ident_11 = ident_block(ident_10 , (256 , 256 , 1024) , (1,3,1))\n",
        "\n",
        "\n",
        "# Stage 5\n",
        "conv_5 = conv_block(ident_11 , (512 , 512 , 2048) , (1,3,1))\n",
        "ident_12 = ident_block(conv_5 , (512 , 512 , 2048) , (1,3,1))\n",
        "ident_13= ident_block(ident_12 , (512 , 512 , 2048) , (1,3,1))\n",
        "\n",
        "\n",
        "# Average Pool\n",
        "avg_pool =  AveragePooling2D((2,2))(ident_13)\n",
        "\n",
        "# FC\n",
        "flatten = Flatten()(avg_pool)\n",
        "dense = Dense(num_classes , activation= 'softmax' )(flatten)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs = X_in , outputs = dense )\n",
        "\n",
        "############################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 7.1903 - acc: 0.4710 - val_loss: 1.8785 - val_acc: 0.7838\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 126s 2ms/step - loss: 0.1040 - acc: 0.9685 - val_loss: 0.0822 - val_acc: 0.9767\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0437 - acc: 0.9864 - val_loss: 2.2148 - val_acc: 0.8203\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0421 - acc: 0.9894 - val_loss: 0.1133 - val_acc: 0.9695\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0225 - acc: 0.9929 - val_loss: 0.0380 - val_acc: 0.9873\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0272 - val_acc: 0.9919\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0354 - val_acc: 0.9894\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.1542 - val_acc: 0.9579\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0412 - val_acc: 0.9883\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0662 - val_acc: 0.9854\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0665 - val_acc: 0.9837\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0260 - val_acc: 0.9929\n",
            "Test loss: 0.02602897907351844\n",
            "Test accuracy: 0.9929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo7ZBITbL6I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}